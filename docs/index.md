## Repository with interactive attention maps generated from table language models.

The visualizations have been created using the [BertViz tool](https://github.com/jessevig/bertviz).


The model view for TaBERT shows the attention maps for the 12 layers, each with 12 heads. 
On each of the heads can be clicked and a zoomed view will appear where the tokens are also visible. 

[Link](https://anetakoleva.github.io/attention_analysis_TaLMs/tabert_model_view.html)
